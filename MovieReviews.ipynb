{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEFINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Define the problem ----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this project is to analyze the movie review statements left by customers in order to determine the sentiment.  Sarcasm and use of certain adjectives might lead to false positive and false negative statements. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##install packages\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Load the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read in csv\n",
    "import pandas as p\n",
    "train=p.read_csv(\"/Users/arielledortch/Downloads/kaggle-sentiment/train.tsv\", delimiter='\\t')\n",
    "y=train['Sentiment'].values\n",
    "X=train['Phrase'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636,) (93636,) (62424,) (62424,)\n",
      "almost in a class with that of Wilde\n",
      "3\n",
      "escape movie\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "print(X_train[0])\n",
    "print(y_train[0])\n",
    "print(X_test[0])\n",
    "print(y_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DISCOVER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Examine the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4}\n",
      "[[    0  4141]\n",
      " [    1 16449]\n",
      " [    2 47718]\n",
      " [    3 19859]\n",
      " [    4  5469]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arielledortch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Check how many training examples in each category\n",
    "# this is important to see whether the data set is balanced or skewed\n",
    "\n",
    "training_labels = set(y_train)\n",
    "print(training_labels)\n",
    "from scipy.stats import itemfreq\n",
    "training_category_dist = itemfreq(y_train)\n",
    "print(training_category_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0, 1, 2, 3, 4}\n",
      "[[    0  2931]\n",
      " [    1 10824]\n",
      " [    2 31864]\n",
      " [    3 13068]\n",
      " [    4  3737]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arielledortch/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: DeprecationWarning: `itemfreq` is deprecated!\n",
      "`itemfreq` is deprecated and will be removed in a future version. Use instead `np.unique(..., return_counts=True)`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Check how many testing examples in each category\n",
    "# this is important to see whether the data set is balanced or skewed\n",
    "\n",
    "testing_labels = set(y_test)\n",
    "print(testing_labels)\n",
    "from scipy.stats import itemfreq\n",
    "testing_category_dist = itemfreq(y_test)\n",
    "print(testing_category_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Vectorize the data ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the sklearn documentation to understand all vectorization options\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# several commonly used vectorizer setting\n",
    "\n",
    "#  unigram boolean vectorizer, set minimum document frequency to 5\n",
    "unigram_bool_vectorizer = CountVectorizer(encoding='latin-1', binary=True, min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram term frequency vectorizer, set minimum document frequency to 5\n",
    "unigram_count_vectorizer = CountVectorizer(encoding='latin-1', binary=False, min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram and bigram term frequency vectorizer, set minimum document frequency to 5\n",
    "bigram_count_vectorizer = CountVectorizer(encoding='latin-1', ngram_range=(1,2), min_df=5, stop_words='english')\n",
    "\n",
    "#  unigram tfidf vectorizer, set minimum document frequency to 5\n",
    "unigram_tfidf_vectorizer = TfidfVectorizer(encoding='latin-1', use_idf=True, min_df=5, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93636, 11967)\n",
      "[[0 0 0 ... 0 0 0]]\n",
      "11967\n",
      "[('class', 1858), ('wilde', 11742), ('derring', 2802), ('chilling', 1764), ('affecting', 313), ('meanspirited', 6557), ('personal', 7662), ('low', 6296), ('involved', 5602), ('worth', 11868)]\n"
     ]
    }
   ],
   "source": [
    "# The vectorizer can do \"fit\" and \"transform\"\n",
    "# fit is a process to collect unique tokens into the vocabulary\n",
    "# transform is a process to convert each document to vector based on the vocabulary\n",
    "# These two processes can be done together using fit_transform(), or used individually: fit() or transform()\n",
    "\n",
    "# fit vocabulary in training documents and transform the training documents into vectors\n",
    "X_train_vec = unigram_count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# check the content of a document vector\n",
    "print(X_train_vec.shape)\n",
    "print(X_train_vec[0].toarray())\n",
    "\n",
    "# check the size of the constructed vocabulary\n",
    "print(len(unigram_count_vectorizer.vocabulary_))\n",
    "\n",
    "# print out the first 10 items in the vocabulary\n",
    "print(list(unigram_count_vectorizer.vocabulary_.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62424, 11967)\n"
     ]
    }
   ],
   "source": [
    "# use the vocabulary constructed from the training data to vectorize the test data. \n",
    "# Therefore, use \"transform\" only, not \"fit_transform\", \n",
    "# otherwise \"fit\" would generate a new vocabulary from the test data\n",
    "\n",
    "X_test_vec = unigram_count_vectorizer.transform(X_test)\n",
    "\n",
    "# print out #examples and #features in the test set\n",
    "print(X_test_vec.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEVELOP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ---- Create models ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the MNB module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "nb_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.606401384083045"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf.score(X_test_vec,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  742  1276   797   105    11]\n",
      " [  614  4126  5397   655    32]\n",
      " [  248  2385 25756  3239   236]\n",
      " [   19   456  5570  6253   770]\n",
      " [    1    53   729  1977   977]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred = nb_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "cm=confusion_matrix(y_test, y_pred, labels=[0,1,2,3,4])\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.45689655 0.49734812 0.67337708 0.51132554 0.482231  ]\n",
      "[0.25315592 0.38118995 0.80831032 0.47849709 0.26143966]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.25      0.33      2931\n",
      "           1       0.50      0.38      0.43     10824\n",
      "           2       0.67      0.81      0.73     31864\n",
      "           3       0.51      0.48      0.49     13068\n",
      "           4       0.48      0.26      0.34      3737\n",
      "\n",
      "   micro avg       0.61      0.61      0.61     62424\n",
      "   macro avg       0.52      0.44      0.47     62424\n",
      "weighted avg       0.59      0.61      0.59     62424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "print(precision_score(y_test, y_pred, average=None))\n",
    "print(recall_score(y_test, y_pred, average=None))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "target_names = ['0','1','2','3','4']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very Negative\n",
      "(-5.941598005980322, 'time')\n",
      "(-5.931015896649785, 'characters')\n",
      "(-5.92054459678249, 'minutes')\n",
      "(-5.92054459678249, 'story')\n",
      "(-5.910181809746943, 'comedy')\n",
      "(-5.689102242653584, 'just')\n",
      "(-5.137785257532857, 'like')\n",
      "(-4.975504451622348, 'bad')\n",
      "(-4.832403607981675, 'film')\n",
      "(-4.3215779842156845, 'movie')\n",
      "\n",
      "Very Positive\n",
      "(-10.484892788250326, '102')\n",
      "(-10.484892788250326, '10th')\n",
      "(-10.484892788250326, '127')\n",
      "(-10.484892788250326, '13th')\n",
      "(-10.484892788250326, '14')\n",
      "(-10.484892788250326, '16')\n",
      "(-10.484892788250326, '163')\n",
      "(-10.484892788250326, '168')\n",
      "(-10.484892788250326, '170')\n",
      "(-10.484892788250326, '1790')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_ranks = sorted(zip(nb_clf.coef_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "\n",
    "## get the 10 features that are best indicators of very negative sentiment (they are at the bottom of the ranked list)\n",
    "very_negative_10 = feature_ranks[-10:]\n",
    "print(\"Very Negative\")\n",
    "for i in range(0, len(very_negative_10)):\n",
    "    print(very_negative_10[i])\n",
    "print()\n",
    "\n",
    "## get 10 features that are least relevant to \"very negative\" sentiment (they are at the top of the ranked list)\n",
    "not_very_negative_10 = feature_ranks[:10]\n",
    "print(\"Very Positive\")\n",
    "for i in range(0, len(not_very_negative_10)):\n",
    "    print(not_very_negative_10[i])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the LinearSVC module\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "# initialize the LinearSVC model\n",
    "svm_clf = LinearSVC(C=1)\n",
    "\n",
    "# use the training data to train the model\n",
    "svm_clf.fit(X_train_vec,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  918  1221   697    82    13]\n",
      " [  701  4080  5504   514    25]\n",
      " [  195  2106 27081  2310   172]\n",
      " [   34   396  6048  5533  1057]\n",
      " [    3    51   590  1772  1321]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_pred2 = svm_clf.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "cm2=confusion_matrix(y_test, y_pred2, labels=[0,1,2,3,4])\n",
    "print(cm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49594814 0.51948052 0.67838176 0.54186661 0.51043277]\n",
      "[0.31320368 0.37694013 0.8498933  0.42340067 0.35349211]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.31      0.38      2931\n",
      "           1       0.52      0.38      0.44     10824\n",
      "           2       0.68      0.85      0.75     31864\n",
      "           3       0.54      0.42      0.48     13068\n",
      "           4       0.51      0.35      0.42      3737\n",
      "\n",
      "   micro avg       0.62      0.62      0.62     62424\n",
      "   macro avg       0.55      0.46      0.49     62424\n",
      "weighted avg       0.60      0.62      0.60     62424\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print classification report\n",
    "\n",
    "print(precision_score(y_test, y_pred2, average=None))\n",
    "print(recall_score(y_test, y_pred2, average=None))\n",
    "target_names = ['0','1','2','3','4']\n",
    "print(classification_report(y_test, y_pred2, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very Negative\n",
      "(1.62160999004353, 'cesspool')\n",
      "(1.6484881338928794, 'disappointment')\n",
      "(1.6592494240393827, 'pompous')\n",
      "(1.6683696592808896, 'stinks')\n",
      "(1.6927739439360225, 'distasteful')\n",
      "(1.6955904869852574, 'unwatchable')\n",
      "(1.7526397573716288, 'unbearable')\n",
      "(1.7873567405771817, 'stinker')\n",
      "(1.8228706330454685, 'disgusting')\n",
      "(1.8233057147577225, 'worthless')\n",
      "\n",
      "Very Positive\n",
      "(-1.8329269147029115, 'hawke')\n",
      "(-1.7372807353160562, 'giddy')\n",
      "(-1.6832953441761966, 'collar')\n",
      "(-1.5847292421661077, 'swimfan')\n",
      "(-1.5720764835196204, 'blue')\n",
      "(-1.4801113634537777, 'dogtown')\n",
      "(-1.4138361223835711, 'clamoring')\n",
      "(-1.409353239619115, 'joan')\n",
      "(-1.3918162689843427, 'victim')\n",
      "(-1.3400001519321338, 'compulsively')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Linear SVC also ranks all features based on their contribution to distinguish the two concepts in each binary classifier\n",
    "## For category \"0\" (very negative), get all features and their weights and sort them in increasing order\n",
    "feature_ranks = sorted(zip(svm_clf.coef_[0], unigram_count_vectorizer.get_feature_names()))\n",
    "\n",
    "## get the 10 features that are best indicators of very negative sentiment (they are at the bottom of the ranked list)\n",
    "very_negative_10 = feature_ranks[-10:]\n",
    "print(\"Very Negative\")\n",
    "for i in range(0, len(very_negative_10)):\n",
    "    print(very_negative_10[i])\n",
    "print()\n",
    "\n",
    "## get 10 features that are least relevant to \"very negative\" sentiment (they are at the top of the ranked list)\n",
    "not_very_negative_10 = feature_ranks[:10]\n",
    "print(\"Very Positive\")\n",
    "for i in range(0, len(not_very_negative_10)):\n",
    "    print(not_very_negative_10[i])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55, 61)\n",
      "[[1 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 3\n",
      "  2 0 0 0 1 2 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "61\n",
      "[('restaurant', 41), ('overall', 36), ('ordered', 35), ('really', 40), ('good', 21), ('sauce', 44), ('best', 3), ('amazing', 0), ('experience', 14), ('service', 46)]\n"
     ]
    }
   ],
   "source": [
    "### Task 2 ####\n",
    "# The vectorizer can do \"fit\" and \"transform\"\n",
    "# fit is a process to collect unique tokens into the vocabulary\n",
    "# transform is a process to convert each document to vector based on the vocabulary\n",
    "# These two processes can be done together using fit_transform(), or used individually: fit() or transform()\n",
    "\n",
    "# fit vocabulary in training documents and transform the training documents into vectors\n",
    "X_train_vec2 = bigram_count_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# check the content of a document vector\n",
    "print(X_train_vec2.shape)\n",
    "print(X_train_vec2[0].toarray())\n",
    "\n",
    "# check the size of the constructed vocabulary\n",
    "print(len(bigram_count_vectorizer.vocabulary_))\n",
    "\n",
    "# print out the first 10 items in the vocabulary\n",
    "print(list(bigram_count_vectorizer.vocabulary_.items())[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 61)\n"
     ]
    }
   ],
   "source": [
    "# use the vocabulary constructed from the training data to vectorize the test data. \n",
    "# Therefore, use \"transform\" only, not \"fit_transform\", \n",
    "# otherwise \"fit\" would generate a new vocabulary from the test data\n",
    "\n",
    "X_test_vec2 = bigram_count_vectorizer.transform(X_test)\n",
    "\n",
    "# print out #examples and #features in the test set\n",
    "print(X_test_vec2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the MNB module\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# initialize the MNB model\n",
    "nb_clf2= MultinomialNB()\n",
    "\n",
    "# use the training data to train the MNB model\n",
    "nb_clf2.fit(X_train_vec2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8947368421052632"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_clf2.score(X_test_vec2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8 0]\n",
      " [2 9]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "y_pred3 = nb_clf2.fit(X_train_vec2, y_train).predict(X_test_vec2)\n",
    "cm3=confusion_matrix(y_test, y_pred3, labels=['p','n'])\n",
    "print(cm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  0.8]\n",
      "[0.81818182 1.        ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           p       1.00      0.82      0.90        11\n",
      "           n       0.80      1.00      0.89         8\n",
      "\n",
      "   micro avg       0.89      0.89      0.89        19\n",
      "   macro avg       0.90      0.91      0.89        19\n",
      "weighted avg       0.92      0.89      0.90        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred3, average=None))\n",
    "print(recall_score(y_test, y_pred3, average=None))\n",
    "target_names = ['p','n']\n",
    "print(classification_report(y_test, y_pred3, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the LinearSVC model\n",
    "svm_clf2 = LinearSVC(C=1)\n",
    "\n",
    "# use the training data to train the model\n",
    "svm_clf2.fit(X_train_vec2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7894736842105263"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf2.score(X_test_vec2,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  3]\n",
      " [ 1 10]]\n"
     ]
    }
   ],
   "source": [
    "# print confusion matrix (row: ground truth; col: prediction)\n",
    "\n",
    "y_pred4 = svm_clf2.fit(X_train_vec2, y_train).predict(X_test_vec2)\n",
    "cm4=confusion_matrix(y_test, y_pred4, labels=['p','n'])\n",
    "print(cm4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76923077 0.83333333]\n",
      "[0.90909091 0.625     ]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           p       0.77      0.91      0.83        11\n",
      "           n       0.83      0.62      0.71         8\n",
      "\n",
      "   micro avg       0.79      0.79      0.79        19\n",
      "   macro avg       0.80      0.77      0.77        19\n",
      "weighted avg       0.80      0.79      0.78        19\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(precision_score(y_test, y_pred4, average=None))\n",
    "print(recall_score(y_test, y_pred4, average=None))\n",
    "target_names = ['p','n']\n",
    "print(classification_report(y_test, y_pred4, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEPLOY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_test=pd.read_csv(\"/Users/arielledortch/Downloads/kaggle-sentiment/test.tsv\", delimiter='\\t') \n",
    "# preserve the id column of the test examples \n",
    "kaggle_ids=kaggle_test['PhraseId'].values \n",
    "# read in the text content of the examples \n",
    "kaggle_X_test=kaggle_test['Phrase'].values \n",
    "# vectorize the test examples using the vocabulary fitted from the 60% training data \n",
    "kaggle_X_test_vec=unigram_count_vectorizer.transform(kaggle_X_test) \n",
    "# predict using the NB classifier that we built \n",
    "kaggle_pred=svm_clf.fit(X_train_vec, y_train).predict(kaggle_X_test_vec) \n",
    "# combine the test example ids with their predictions \n",
    "kaggle_submission=zip(kaggle_ids, kaggle_pred) \n",
    "# prepare output file \n",
    "outf=open('kaggle_SVC_submission.csv', 'w') \n",
    "# write header outf.write('PhraseId,Sentiment\\n') # write predictions with ids to the output file \n",
    "for x, value in enumerate(kaggle_submission): \n",
    "    outf.write(str(value[0]) + ',' + str(value[1]) + '\\n') \n",
    "    # close the output file \n",
    "    outf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
